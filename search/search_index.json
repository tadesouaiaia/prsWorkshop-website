{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PRS Japan Workshop is Almost Here!: Aug 31, 2024 Attendees should complete the pre-workshop checklist! Download pre-workshop materials for Linux ( Link ) or macOS ( Link ). This short workshop will equip scientists with the tools and approaches required to perform polygenic risk score (PRS) analyses. The workshop will include both applied and theoretical topics in PRS research, delivered across multiple lectures, seminars and computational practicals. In order that students are properly prepared for the workshop, then they must complete this \"Pre-Workshop Guide\" first, by going through each of the sections shown on the left of the screen, starting with 'Checklist'.","title":"Home"},{"location":"#prs-japan-workshop-is-almost-here-aug-31-2024","text":"Attendees should complete the pre-workshop checklist! Download pre-workshop materials for Linux ( Link ) or macOS ( Link ). This short workshop will equip scientists with the tools and approaches required to perform polygenic risk score (PRS) analyses. The workshop will include both applied and theoretical topics in PRS research, delivered across multiple lectures, seminars and computational practicals. In order that students are properly prepared for the workshop, then they must complete this \"Pre-Workshop Guide\" first, by going through each of the sections shown on the left of the screen, starting with 'Checklist'.","title":"PRS Japan Workshop is Almost Here!: Aug 31, 2024"},{"location":"misc_linux/","text":"Linux for Windows Users For windows users, a single WSL command can be used to install linux. Detailed information on WSL can be found on the microsoft website and step-by-step video obstructions can be found here . These steps involve: Installation Using Administrator Mode to Installing Linux Open PowerShell or Windows Command Prompt by right-clicking and selecting \"Run as administrator\", and type: wsl --install Ubuntu This command will enable the features necessary to run WSL, restart your computer, and install the Ubuntu distribution of Linux. After it has been installed you will need to create a new username and password, to learn more about this please see microsoft best practices Setup Once Linux has been installed and you have created a new account you can run Ubuntu using windows terminal or by going to the start menu and typing \"Ubuntu\". Additionally, you should see that Ubuntu has been added to your applications and that there is a Ubuntu Folder on your computer (alongside Desktop, Downloads, etc). Double clicking the Ubuntu app will open up the Ubuntu terminal in the Ubuntu folder . You should see many sub-folders within the Ubuntu folder (such as bin, home, etc, etc.) . You can view them using terminal commands or by double-clicking on them. If you go into the home/ folder you should see another folder with your username. This folder ( home/(your username)/ ) is where you should store your workshop folders and run programs during the workshop. Once you have successfully installed Ubuntu, you can follow the rest of the pre-workshop tutorial using the Linux instructions.","title":"Linux For Windows"},{"location":"misc_linux/#linux-for-windows-users","text":"For windows users, a single WSL command can be used to install linux. Detailed information on WSL can be found on the microsoft website and step-by-step video obstructions can be found here . These steps involve:","title":"Linux for Windows Users"},{"location":"misc_linux/#installation","text":"Using Administrator Mode to Installing Linux Open PowerShell or Windows Command Prompt by right-clicking and selecting \"Run as administrator\", and type: wsl --install Ubuntu This command will enable the features necessary to run WSL, restart your computer, and install the Ubuntu distribution of Linux. After it has been installed you will need to create a new username and password, to learn more about this please see microsoft best practices","title":"Installation"},{"location":"misc_linux/#setup","text":"Once Linux has been installed and you have created a new account you can run Ubuntu using windows terminal or by going to the start menu and typing \"Ubuntu\". Additionally, you should see that Ubuntu has been added to your applications and that there is a Ubuntu Folder on your computer (alongside Desktop, Downloads, etc). Double clicking the Ubuntu app will open up the Ubuntu terminal in the Ubuntu folder . You should see many sub-folders within the Ubuntu folder (such as bin, home, etc, etc.) . You can view them using terminal commands or by double-clicking on them. If you go into the home/ folder you should see another folder with your username. This folder ( home/(your username)/ ) is where you should store your workshop folders and run programs during the workshop. Once you have successfully installed Ubuntu, you can follow the rest of the pre-workshop tutorial using the Linux instructions.","title":"Setup"},{"location":"misc_plink_problem/","text":"Plink: Developer Cannot Be Verified If you see this error, Do not click: Move To Trash . Instead click on the top right hand corner of the box, or stop running whatever program you are using and follow these instructions to give your system permission to run downloaded software. 1- Default Settings By default macOS allows you to open apps from the official Mac App Store only, If you have this set as your default you can change this if you: Open System Preferences. Go to the Security & Privacy tab. Click on the lock and enter your password. Change settings to include identified developers (see below): 2- Allowing Exceptions Expanding permissions to include \"identified developers\" is required but not sufficient. To obtain further permission to run Plink or any other unapproved program you can: Open System Preferences. Go to Security & Privacy and select the General tab. If this has happened within the hour, this page will give you an override button to open Open Anyway . Enter you password as above and click this button. You will be asked to once more which will create an exception allowing you to run Plink in the future. 3- Downstream BridgePRS Errors If you have moved plink to the trash you will have to recover it, additionally the empty files created by a failed attempt to run Plink can cause problems if BridgePRS tries to recover your progress. Restarting a bridgePRS run You can avoid this problem by manually deleting your output directory and starting over, or by using the restart flag: $./bridgePRS easyrun go -o out1 --pop_configs data/afr.config data/eur.config --phenotype y --restart This will force bridgePRS to restart every subprogram from the beginning.","title":"Mac Security"},{"location":"misc_plink_problem/#plink-developer-cannot-be-verified","text":"If you see this error, Do not click: Move To Trash . Instead click on the top right hand corner of the box, or stop running whatever program you are using and follow these instructions to give your system permission to run downloaded software.","title":"Plink: Developer Cannot Be Verified"},{"location":"misc_plink_problem/#1-default-settings","text":"By default macOS allows you to open apps from the official Mac App Store only, If you have this set as your default you can change this if you: Open System Preferences. Go to the Security & Privacy tab. Click on the lock and enter your password. Change settings to include identified developers (see below):","title":"1- Default Settings"},{"location":"misc_plink_problem/#2-allowing-exceptions","text":"Expanding permissions to include \"identified developers\" is required but not sufficient. To obtain further permission to run Plink or any other unapproved program you can: Open System Preferences. Go to Security & Privacy and select the General tab. If this has happened within the hour, this page will give you an override button to open Open Anyway . Enter you password as above and click this button. You will be asked to once more which will create an exception allowing you to run Plink in the future.","title":"2- Allowing Exceptions"},{"location":"misc_plink_problem/#3-downstream-bridgeprs-errors","text":"If you have moved plink to the trash you will have to recover it, additionally the empty files created by a failed attempt to run Plink can cause problems if BridgePRS tries to recover your progress. Restarting a bridgePRS run You can avoid this problem by manually deleting your output directory and starting over, or by using the restart flag: $./bridgePRS easyrun go -o out1 --pop_configs data/afr.config data/eur.config --phenotype y --restart This will force bridgePRS to restart every subprogram from the beginning.","title":"3- Downstream BridgePRS Errors"},{"location":"prep_list/","text":"Introduction Here we present a pre-workshop preparation guide to get students sufficiently prepared before the workshop begins. In this guide we help students set up the operating system (Linux or macOS), provide tutorials for Bash, R, and Python for students who are unfamiliar or need a refresher, and help students verify that their system is capable of running the software necessary for the workshop. Reminder: All students must complete pre-workship testing and verification At the end of this guide, students are led through a series of software tests . The tests are required to verify that student laptops are properly set-up before the workshop. Students unable to properly configure their laptops should email: tade.souaiaia@downstate.edu Checklist This checklist will help guide you through the pre-workshop requirements: Operating System : Confirm or install a compatible operating system. Terminal Setup : Setting up the terminal, creating workshop directory. Software Installations : Confirm/Install R, Python3, and Plink as well their as required libraries. Software Tutorials : If unfamiliar with bash, R, or python, please complete the included tutorials. Verification/Testing : Download materials, test that everything is in working order ( Required ).","title":"Checklist"},{"location":"prep_list/#introduction","text":"Here we present a pre-workshop preparation guide to get students sufficiently prepared before the workshop begins. In this guide we help students set up the operating system (Linux or macOS), provide tutorials for Bash, R, and Python for students who are unfamiliar or need a refresher, and help students verify that their system is capable of running the software necessary for the workshop. Reminder: All students must complete pre-workship testing and verification At the end of this guide, students are led through a series of software tests . The tests are required to verify that student laptops are properly set-up before the workshop. Students unable to properly configure their laptops should email: tade.souaiaia@downstate.edu","title":"Introduction"},{"location":"prep_list/#checklist","text":"This checklist will help guide you through the pre-workshop requirements: Operating System : Confirm or install a compatible operating system. Terminal Setup : Setting up the terminal, creating workshop directory. Software Installations : Confirm/Install R, Python3, and Plink as well their as required libraries. Software Tutorials : If unfamiliar with bash, R, or python, please complete the included tutorials. Verification/Testing : Download materials, test that everything is in working order ( Required ).","title":"Checklist"},{"location":"prep_os/","text":"Operating System This workshop is designed to help students run statistical genetic analysis. In practice large-scale data analysis is almost always done using a server or cloud-based system running a Linux operating system. For this reason a Linux based operating system is recommended and users running MacOs ( see here ) or Windows ( see here ) are encouraged to install Linux if possible. However, due to the similarity between Unix based operating systems, this workshop and tutorial can be completed in Linux and macOs environments and is described for users with both operating systems. Microsoft windows users are required to install Linux and as such, we provide detailed instructions to do so. This workshop is designed for either of the following operating systems: Linux: A Debian compatible Linux based operating system (Ubuntu, Mint, etc). macOS: A recent version (11+) of the Desktop OS. Microsoft Windows is not supported, but instructions to install Linux can be found here.","title":"Operating System"},{"location":"prep_os/#operating-system","text":"This workshop is designed to help students run statistical genetic analysis. In practice large-scale data analysis is almost always done using a server or cloud-based system running a Linux operating system. For this reason a Linux based operating system is recommended and users running MacOs ( see here ) or Windows ( see here ) are encouraged to install Linux if possible. However, due to the similarity between Unix based operating systems, this workshop and tutorial can be completed in Linux and macOs environments and is described for users with both operating systems. Microsoft windows users are required to install Linux and as such, we provide detailed instructions to do so. This workshop is designed for either of the following operating systems: Linux: A Debian compatible Linux based operating system (Ubuntu, Mint, etc). macOS: A recent version (11+) of the Desktop OS. Microsoft Windows is not supported, but instructions to install Linux can be found here.","title":"Operating System"},{"location":"prep_software/","text":"Required System Software This workshop requires that the following software be installed and tested before the workshop: Name/Link Description Additional Requirements 1. R Most popular analysis program in statistical genetics Yes (Specific Libraries). 2. Python 3 . Multi purpose Programming Language Yes (The matplotlib library). Both popular computer languages, R and python3 will be used during the workshop. Here we will provide a guide for installation of both languages and their associated libraries. 1. R (and associated packages) R is the most popular analysis program in statistical genetics, and required for most genetic analysis. We recommend that MacOS users download an up-to-date (4.4.1) version directly from the R website and using the R installer. If you are having trouble we recommend this video tutorial . While Linux users can also find a suitable version on the website, we recommend using the package installer that comes with Debian based distributions (Debian, Ubuntu, Mint, etc) and downloading R directly using the following terminal commands: sudo apt install r-base # to install R sudo apt install build-essential # to install the essential packages Important: Additional R Packages Are Required This workshop requires the following non-standard R packages: BEDMatrix, boot, data.table, doMC, glmnet, MASS, optparse, parallel, and R.utils These packages can be installed by opening up an R session from within the terminal, by typing: R And typing the following command: install.packages(c(\"BEDMatrix\",\"boot\",\"data.table\",\"doMC\",\"glmnet\",\"MASS\",\"optparse\",\"parallel\",\"R.utils\")) After you have finished installation and testing of R, please consider completing our R-tutorial to better familiarize yourself with some basic analysis commands. 2. Python3 (and matplotlib) Python3 is a popular multiuse programming language. This workshop requires Python3 and the matplotlib library. Any version of Python3 is acceptable but a newer version Python3.10.10+ is recommended. Many systems come installed with Python3 by default, but it can be downloaded from the python website . The matplotlib package can be found here . Users of macOs can find detailed instructions on how to install python3 by visiting the following video link that we find very helpful. After installing python3, macOs users can install matplotlib using pip: python3 -m ensurepip sudo python3 -m pip install -U matplotlib For Linux we again recommend that you use the package installer to install python3 and matplotlib sudo apt install python3 # to install python3 python3 --version # to verify that it worked sudo apt-get install python3-matplotlib # to install matplotlib After you have finished with this section, don't forget to complete our Python tutorial to familiarize yourself with some basic commands.","title":"Software Installs"},{"location":"prep_software/#required-system-software","text":"This workshop requires that the following software be installed and tested before the workshop: Name/Link Description Additional Requirements 1. R Most popular analysis program in statistical genetics Yes (Specific Libraries). 2. Python 3 . Multi purpose Programming Language Yes (The matplotlib library). Both popular computer languages, R and python3 will be used during the workshop. Here we will provide a guide for installation of both languages and their associated libraries.","title":"Required System Software"},{"location":"prep_software/#1-r-and-associated-packages","text":"R is the most popular analysis program in statistical genetics, and required for most genetic analysis. We recommend that MacOS users download an up-to-date (4.4.1) version directly from the R website and using the R installer. If you are having trouble we recommend this video tutorial . While Linux users can also find a suitable version on the website, we recommend using the package installer that comes with Debian based distributions (Debian, Ubuntu, Mint, etc) and downloading R directly using the following terminal commands: sudo apt install r-base # to install R sudo apt install build-essential # to install the essential packages Important: Additional R Packages Are Required This workshop requires the following non-standard R packages: BEDMatrix, boot, data.table, doMC, glmnet, MASS, optparse, parallel, and R.utils These packages can be installed by opening up an R session from within the terminal, by typing: R And typing the following command: install.packages(c(\"BEDMatrix\",\"boot\",\"data.table\",\"doMC\",\"glmnet\",\"MASS\",\"optparse\",\"parallel\",\"R.utils\")) After you have finished installation and testing of R, please consider completing our R-tutorial to better familiarize yourself with some basic analysis commands.","title":"1. R (and associated packages)"},{"location":"prep_software/#2-python3-and-matplotlib","text":"Python3 is a popular multiuse programming language. This workshop requires Python3 and the matplotlib library. Any version of Python3 is acceptable but a newer version Python3.10.10+ is recommended. Many systems come installed with Python3 by default, but it can be downloaded from the python website . The matplotlib package can be found here . Users of macOs can find detailed instructions on how to install python3 by visiting the following video link that we find very helpful. After installing python3, macOs users can install matplotlib using pip: python3 -m ensurepip sudo python3 -m pip install -U matplotlib For Linux we again recommend that you use the package installer to install python3 and matplotlib sudo apt install python3 # to install python3 python3 --version # to verify that it worked sudo apt-get install python3-matplotlib # to install matplotlib After you have finished with this section, don't forget to complete our Python tutorial to familiarize yourself with some basic commands.","title":"2. Python3 (and matplotlib)"},{"location":"prep_terminal/","text":"Setting up the Terminal Terminal programs allow you to navigate the Unix-Based OS, a simple system made up of files and folders. For this workshop, basic familiarity is required. Here we will go over setting up your terminal. If you are unfamiliar with the terminal afterwards it is recommended you complete our bash tutorial . To begin open up a terminal window, by: macOS: Searching for \"terminal\" on top toolbar, or going to Applications/Utilities/ and clicking the icon. Linux: Opening the lower left hand start menu, typing \"terminal\" and clicking on the icon. Note: Users running Ubuntu in Windows can follow the Linux directions after double clicking the Ubuntu App icon to bring up the terminal A window will open up that looks something like this: Bash Type: cd ~ The cd command (learn more) stands for change directory, and ~ represents a shortcut to your \"home\" directory. After typing this command, you are \"in\" your home directory. Now type: pwd The pwd command returns your current \"path\", which represents the name and location of your home directory. Depending on your machine typing pwd from your home directory may return: /home/(your username) (most Linux environments) /Users/(your username) (older macOs, shared systems) Something else. Because the name, location, and syntax differs from computer to computer, we use $HOME as a universal shortcut to represent your home directory. The command ls (learn_more) lists the files and folders in your home directory. These files and folders in the home directory will differ from computer to computer, but most filesystems will have a Desktop and Downloads folder in the home directory: Often the home directory of the filesystem can be quite crowded, which is why we would like to carry out this tutorial in a new directory specifically for the workshop. To create this directory, type: mkdir prsworkshop The mkdir command makes a new directory called prsworkshop that is located in your home directory: Next we can move to this newly created directory by typing: cd prsworkshop Now we will create a file using the program nano by typing: nano test.sh This command will open up the nano text editor: On the top line type: echo \"hello world\" Then save the file using Ctrl-O and press enter, and quit using Ctrl-X and pressing enter. Now type: ls Do you see the file you just created? To see the contents of the file you just created you can type: cat test.sh Do you know that the file you just created can also run as program? To execute the bash code that you have created you can type: bash test.sh Congratulations, you have now navigated the filesystem, created a directory, created a file and executed a program! You may feel like somewhat of an expert. However, if you still feel unfamiliar with shell scripting, please consider completing our longer bash tutorial . Otherwise, proceed to the next step, where you will install all system wide software necessary for the workshop.","title":"Terminal Setup"},{"location":"prep_terminal/#setting-up-the-terminal","text":"Terminal programs allow you to navigate the Unix-Based OS, a simple system made up of files and folders. For this workshop, basic familiarity is required. Here we will go over setting up your terminal. If you are unfamiliar with the terminal afterwards it is recommended you complete our bash tutorial . To begin open up a terminal window, by: macOS: Searching for \"terminal\" on top toolbar, or going to Applications/Utilities/ and clicking the icon. Linux: Opening the lower left hand start menu, typing \"terminal\" and clicking on the icon. Note: Users running Ubuntu in Windows can follow the Linux directions after double clicking the Ubuntu App icon to bring up the terminal A window will open up that looks something like this:","title":"Setting up the Terminal"},{"location":"prep_terminal/#bash","text":"Type: cd ~ The cd command (learn more) stands for change directory, and ~ represents a shortcut to your \"home\" directory. After typing this command, you are \"in\" your home directory. Now type: pwd The pwd command returns your current \"path\", which represents the name and location of your home directory. Depending on your machine typing pwd from your home directory may return: /home/(your username) (most Linux environments) /Users/(your username) (older macOs, shared systems) Something else. Because the name, location, and syntax differs from computer to computer, we use $HOME as a universal shortcut to represent your home directory. The command ls (learn_more) lists the files and folders in your home directory. These files and folders in the home directory will differ from computer to computer, but most filesystems will have a Desktop and Downloads folder in the home directory: Often the home directory of the filesystem can be quite crowded, which is why we would like to carry out this tutorial in a new directory specifically for the workshop. To create this directory, type: mkdir prsworkshop The mkdir command makes a new directory called prsworkshop that is located in your home directory: Next we can move to this newly created directory by typing: cd prsworkshop Now we will create a file using the program nano by typing: nano test.sh This command will open up the nano text editor: On the top line type: echo \"hello world\" Then save the file using Ctrl-O and press enter, and quit using Ctrl-X and pressing enter. Now type: ls Do you see the file you just created? To see the contents of the file you just created you can type: cat test.sh Do you know that the file you just created can also run as program? To execute the bash code that you have created you can type: bash test.sh Congratulations, you have now navigated the filesystem, created a directory, created a file and executed a program! You may feel like somewhat of an expert. However, if you still feel unfamiliar with shell scripting, please consider completing our longer bash tutorial . Otherwise, proceed to the next step, where you will install all system wide software necessary for the workshop.","title":"Bash"},{"location":"prep_testing/","text":"Preworkshop Testing Downloading materials For Linux: Link. For macOS: Link. By clicking the link, then the download ( down-arrow ) icon at the top of the screen. If a message comes up that the file can't be scanned for viruses, please click \"download anyway\". You should already have a folder in your home directory named prsworkshop that you created during the terminal part of this guide by typing \"mkdir ~/prsworkshop\". If you haven't created this folder, please do so now. Next, move to this directory by typing: cd ~/prsworkshop Next unzip the downloaded workshop materials and move them to this directory. This can be down by right clicking on the folder to unzip and then dragging it into the prsworkshop folder, or it can be done in the terminal. In Linux this is accomplished by typing: tar -xvzf ~/Downloads/preworkshop_materials_linux.tar.gz -C ~/prsworkshop cd ~/prsworkshop/preworkshop_materials_linux MacOs sometimes unzips downloaded files for you, so macOs users should first type the following: ls ~/Downloads/preworkshop_materials_mac.* If the command returns a file with a \".tar\" ending, then type: tar -xvf ~/Downloads/preworkshop_materials_mac.tar.gz -C ~/prsworkshop Otherwise, if the command returns a file with a \".tar.gz\" ending, type: tar -xvzf ~/Downloads/preworkshop_materials_mac.tar.gz -C ~/prsworkshop To unzip the folder and move it to the appropriate directory. Finally, move to the appropriate directory to begin testing: cd ~/prsworkshop/preworkshop_materials_mac Testing Software Warning For macOs Users: MacOs often block executables if they are not approved from the app store. If you see an error similar to this, when trying to run plink, PRSice, or bridgePRS, DO NOT DELETE THE FILE . You must change your system settings to allow downloaded software. To learn how to do so, please click here . Plink From the preworkshop directory, navigate into the Plink directory. cd Plink and type the following command: ./code/plink -h If no error is observed and a list of options are displayed then your computer is ready to run plink. If you are not already familiar with plink, now is a great time to use the data found in Plink/tutorials/sample_data/ to run the PLINK tutorial . Testing PRSice Please navigate to the correct directory: cd ~/prsworkshop/preworkshop_materials_(mac/linux)/PRSice and type the following command: ./code/PRSice -h # macOs users If no error is observed and a list of options are displayed then your computer is ready to run PRSice. Testing bridgePRS To verify that bridgePRS is able to run navigate to the folder: cd ~/prsworkshop/preworkshop_materials_(mac/linux)/BridgePRS cd bridgePRS and type the command: ./bridgePRS You should see bridge art. If this command works, then type the following command: ./bridgePRS check requirements To confirm that your system is up to date, all libraries are installed and you are ready to run bridgePRS.","title":"Testing"},{"location":"prep_testing/#preworkshop-testing","text":"","title":"Preworkshop Testing"},{"location":"prep_testing/#downloading-materials","text":"For Linux: Link. For macOS: Link. By clicking the link, then the download ( down-arrow ) icon at the top of the screen. If a message comes up that the file can't be scanned for viruses, please click \"download anyway\". You should already have a folder in your home directory named prsworkshop that you created during the terminal part of this guide by typing \"mkdir ~/prsworkshop\". If you haven't created this folder, please do so now. Next, move to this directory by typing: cd ~/prsworkshop Next unzip the downloaded workshop materials and move them to this directory. This can be down by right clicking on the folder to unzip and then dragging it into the prsworkshop folder, or it can be done in the terminal. In Linux this is accomplished by typing: tar -xvzf ~/Downloads/preworkshop_materials_linux.tar.gz -C ~/prsworkshop cd ~/prsworkshop/preworkshop_materials_linux MacOs sometimes unzips downloaded files for you, so macOs users should first type the following: ls ~/Downloads/preworkshop_materials_mac.* If the command returns a file with a \".tar\" ending, then type: tar -xvf ~/Downloads/preworkshop_materials_mac.tar.gz -C ~/prsworkshop Otherwise, if the command returns a file with a \".tar.gz\" ending, type: tar -xvzf ~/Downloads/preworkshop_materials_mac.tar.gz -C ~/prsworkshop To unzip the folder and move it to the appropriate directory. Finally, move to the appropriate directory to begin testing: cd ~/prsworkshop/preworkshop_materials_mac","title":"Downloading materials"},{"location":"prep_testing/#testing-software","text":"Warning For macOs Users: MacOs often block executables if they are not approved from the app store. If you see an error similar to this, when trying to run plink, PRSice, or bridgePRS, DO NOT DELETE THE FILE . You must change your system settings to allow downloaded software. To learn how to do so, please click here .","title":"Testing Software"},{"location":"prep_testing/#plink","text":"From the preworkshop directory, navigate into the Plink directory. cd Plink and type the following command: ./code/plink -h If no error is observed and a list of options are displayed then your computer is ready to run plink. If you are not already familiar with plink, now is a great time to use the data found in Plink/tutorials/sample_data/ to run the PLINK tutorial .","title":"Plink"},{"location":"prep_testing/#testing-prsice","text":"Please navigate to the correct directory: cd ~/prsworkshop/preworkshop_materials_(mac/linux)/PRSice and type the following command: ./code/PRSice -h # macOs users If no error is observed and a list of options are displayed then your computer is ready to run PRSice.","title":"Testing PRSice"},{"location":"prep_testing/#testing-bridgeprs","text":"To verify that bridgePRS is able to run navigate to the folder: cd ~/prsworkshop/preworkshop_materials_(mac/linux)/BridgePRS cd bridgePRS and type the command: ./bridgePRS You should see bridge art. If this command works, then type the following command: ./bridgePRS check requirements To confirm that your system is up to date, all libraries are installed and you are ready to run bridgePRS.","title":"Testing bridgePRS"},{"location":"tut_R/","text":"Introduction to R R is a useful programming language that allows us to perform a variety of statis- tical tests and data manipulation. It can also be used to generate fantastic data visualisations. Here we will go through some of the basics of R so that you can better understand the practicals throughout the workshop. Basics To being type R in the terminal: R Libraries Most functionality of R is organised in packages or libraries. To access these functions, we will have to install and load these packages. Most commonly used packages are installed together with the standard installation process. You can install a new library using the install.packages function. For example, to install ggplot2 , run the command: install.packages(\"ggplot2\") After installation, you can load the library by typing library(ggplot2) Variables in R You can assign a value or values to any variable you want using \\<-. e.g Assign a number to a a <- 1 Assign a vector containing a,b,c to v1 v1 <- c(\"a\", \"b\",\"c\") Functions You can perform lots of operations in R using di\ufb00erent built-in R functions. Some examples are below: Assign number of samples nsample <- 10000 Generate nsample random normal variable with mean = 0 and sd = 1 normal <- rnorm(nsample, mean=0,sd=1) normal.2 <- rnorm(nsample, mean=0,sd=1) We can examine the first few entries of the result using head head(normal) And we can obtain the mean and sd using mean(normal) sd(normal) We can also calculate the correlation between two variables using cor cor(normal, normal.2) Plotting While R contains many powerful plotting functions in its base packages,customisationn can be di\ufb03cult (e.g. changing the colour scales, arranging the axes). ggplot2 is a powerful visualization package that provides extensive flexibility and customi- sation of plots. As an example, we can do the following Load the package library(ggplot2) Specify sample size nsample <-1000 Generate random grouping using sample with replacement groups <- sample(c(\"a\",\"b\"), nsample, replace=T) Now generate the data dat <- data.frame(x=rnorm(nsample), y=rnorm(nsample), groups) Generate a scatter plot with di\ufb00erent coloring based on group ggplot(dat, aes(x=x,y=y,color=groups))+geom_point() Regression Models In statistical modelling, regression analyses are a set of statistical techniques for estimating the relationships among variables or features. We can perform regression analysis in R . Use the following code to perform linear regression on simulated variables \"x\" and \"y\": Simulate data nsample <- 10000 x <- rnorm(nsample) y <- rnorm(nsample) Run linear regression lm(y~x) We can store the result into a variable reg <- lm(y~x) And get a detailed output using summary summary(lm(y~x)) We can also extract the coe\ufb03cient of regression using reg$coe\ufb03cient And we can obtain the residuals by residual <- resid(reg) Examine the first few entries of residuals head(residual) We can also include covariates into the model covar <- rnorm(nsample) lm(y~x+covar) And can even perform interaction analysis lm(y~x+covar+x*covar) Alternatively, we can use the glm function to perform the regression: glm(y~x) For binary traits (case controls studies), logistic regression can be performed using Simulate samples nsample <- 10000 x <- rnorm(nsample) Simulate binary traits (must be coded with 0 and 1) y <- sample(c(0,1), size=nsample, replace=T) Perform logistic regression glm(y~x, family=binomial) Obtain the detailed output summary(glm(y~x, family=binomial))","title":"R Tutorial"},{"location":"tut_R/#introduction-to-r","text":"R is a useful programming language that allows us to perform a variety of statis- tical tests and data manipulation. It can also be used to generate fantastic data visualisations. Here we will go through some of the basics of R so that you can better understand the practicals throughout the workshop.","title":"Introduction to R"},{"location":"tut_R/#basics","text":"To being type R in the terminal: R","title":"Basics"},{"location":"tut_R/#libraries","text":"Most functionality of R is organised in packages or libraries. To access these functions, we will have to install and load these packages. Most commonly used packages are installed together with the standard installation process. You can install a new library using the install.packages function. For example, to install ggplot2 , run the command: install.packages(\"ggplot2\") After installation, you can load the library by typing library(ggplot2)","title":"Libraries"},{"location":"tut_R/#variables-in-r","text":"You can assign a value or values to any variable you want using \\<-. e.g Assign a number to a a <- 1 Assign a vector containing a,b,c to v1 v1 <- c(\"a\", \"b\",\"c\")","title":"Variables in R"},{"location":"tut_R/#functions","text":"You can perform lots of operations in R using di\ufb00erent built-in R functions. Some examples are below: Assign number of samples nsample <- 10000 Generate nsample random normal variable with mean = 0 and sd = 1 normal <- rnorm(nsample, mean=0,sd=1) normal.2 <- rnorm(nsample, mean=0,sd=1) We can examine the first few entries of the result using head head(normal) And we can obtain the mean and sd using mean(normal) sd(normal) We can also calculate the correlation between two variables using cor cor(normal, normal.2)","title":"Functions"},{"location":"tut_R/#plotting","text":"While R contains many powerful plotting functions in its base packages,customisationn can be di\ufb03cult (e.g. changing the colour scales, arranging the axes). ggplot2 is a powerful visualization package that provides extensive flexibility and customi- sation of plots. As an example, we can do the following Load the package library(ggplot2) Specify sample size nsample <-1000 Generate random grouping using sample with replacement groups <- sample(c(\"a\",\"b\"), nsample, replace=T) Now generate the data dat <- data.frame(x=rnorm(nsample), y=rnorm(nsample), groups) Generate a scatter plot with di\ufb00erent coloring based on group ggplot(dat, aes(x=x,y=y,color=groups))+geom_point()","title":"Plotting"},{"location":"tut_R/#regression-models","text":"In statistical modelling, regression analyses are a set of statistical techniques for estimating the relationships among variables or features. We can perform regression analysis in R . Use the following code to perform linear regression on simulated variables \"x\" and \"y\": Simulate data nsample <- 10000 x <- rnorm(nsample) y <- rnorm(nsample) Run linear regression lm(y~x) We can store the result into a variable reg <- lm(y~x) And get a detailed output using summary summary(lm(y~x)) We can also extract the coe\ufb03cient of regression using reg$coe\ufb03cient And we can obtain the residuals by residual <- resid(reg) Examine the first few entries of residuals head(residual) We can also include covariates into the model covar <- rnorm(nsample) lm(y~x+covar) And can even perform interaction analysis lm(y~x+covar+x*covar) Alternatively, we can use the glm function to perform the regression: glm(y~x) For binary traits (case controls studies), logistic regression can be performed using Simulate samples nsample <- 10000 x <- rnorm(nsample) Simulate binary traits (must be coded with 0 and 1) y <- sample(c(0,1), size=nsample, replace=T) Perform logistic regression glm(y~x, family=binomial) Obtain the detailed output summary(glm(y~x, family=binomial))","title":"Regression Models"},{"location":"tut_bash/","text":"Bash/Shell Tutorial The ability to navigate the filesystem using bash is a very important skill in statistical genetics. Bash is a programming language commonly used to navigate the terminal and manipulate files and folders. Some terminals run \"bash-like\" scripting languages like \"zsh\". For the purposes of this tutorial, they are indistinguishable from bash. There are approximately 50 bash commands that used 95% of the time . Here we will review some common commands and do some simple file analysis. Common Commands cd This command is used to change our directory, in the following manner: cd $PATH where $PATH represents the path to the target directory. Common usage of cd includes: cd ~/ # will bring you to your home directory cd $HOME # will bring you to your home directory cd ../ # will bring you to the parent directory (up one level) cd Downloads # will bring you to the Downloads directory, provided that you are in the home directory cd ~/Downloads # will bring you to Downloads, no matter where you are in the filesystem ls This command allows you to look at the contents of a directory: ls Some common usage of ls includes: ls # list the contents of the current directory ls ~ # list the contents of the home directory ls ~/Desktop # Will list the contents of the Desktop For ls , there are a number of additional Unix command options that you can append to it to get additional information, for example: ls -l # shows files as list ls -lh # shows files as a list with human readable format ls -lt # shows the files as a list sorted by time-last-edited ls -lS # shows the files as a list sorted by size mkdir This command to create a new directory in your home folder: mkdir ~/test_directory The following commands should be carried out within this directory Use cd to enter the directory: cd ~/test_directory wsl echo Can be used to print to screen: echo \"Hello\" touch Can be used to create a new (empty) file: touch foo rm Can be used to create delete a file: rm foo > The carrot sign can be used to send the output to a file: echo \"Hello\" > output.txt cat Can be used to print the contents of a file to the screen: cat output.txt cp Can be used to copy a a file: cat output.txt output2.txt nano Nano can be used to edit a file, typing: nano data1.txt Will bring up an editor window: Starting from the top line type: bob 1 fred 2 mary 3 noah 4 sally 5 And then save the file using Ctrl-O and press enter, and quit using Ctrl-X . wc The word count command can be used to count the number of lines or words in a file: wc -l data1.txt grep Can be used to search a file for content: grep \"noah\" data1.text While return all the lines in data1.txt containing the search term \"noah\". File Analysis A very powerful feature of the terminal is the awk programming language, which allows us to extract subsets of a data file, filter data according to some criteria or perform arithmetic operations on the data. awk manipulates a data file by per- forming operations on its columns - this is extremely useful for scientific data sets because typically the columns features or variables of interest. For example, we can use awk to produce a new file that squares the data in our previous file: awk '{print $1,$2*$2}' data1.txt > data2.txt We can also use awk to add up all the squared data values: awk '{X+=$2} END{print $2}' data2.txt","title":"Bash Tutorial"},{"location":"tut_bash/#bashshell-tutorial","text":"The ability to navigate the filesystem using bash is a very important skill in statistical genetics. Bash is a programming language commonly used to navigate the terminal and manipulate files and folders. Some terminals run \"bash-like\" scripting languages like \"zsh\". For the purposes of this tutorial, they are indistinguishable from bash. There are approximately 50 bash commands that used 95% of the time . Here we will review some common commands and do some simple file analysis.","title":"Bash/Shell Tutorial"},{"location":"tut_bash/#common-commands","text":"","title":"Common Commands"},{"location":"tut_bash/#cd","text":"This command is used to change our directory, in the following manner: cd $PATH where $PATH represents the path to the target directory. Common usage of cd includes: cd ~/ # will bring you to your home directory cd $HOME # will bring you to your home directory cd ../ # will bring you to the parent directory (up one level) cd Downloads # will bring you to the Downloads directory, provided that you are in the home directory cd ~/Downloads # will bring you to Downloads, no matter where you are in the filesystem","title":"cd"},{"location":"tut_bash/#ls","text":"This command allows you to look at the contents of a directory: ls Some common usage of ls includes: ls # list the contents of the current directory ls ~ # list the contents of the home directory ls ~/Desktop # Will list the contents of the Desktop For ls , there are a number of additional Unix command options that you can append to it to get additional information, for example: ls -l # shows files as list ls -lh # shows files as a list with human readable format ls -lt # shows the files as a list sorted by time-last-edited ls -lS # shows the files as a list sorted by size","title":"ls"},{"location":"tut_bash/#mkdir","text":"This command to create a new directory in your home folder: mkdir ~/test_directory The following commands should be carried out within this directory Use cd to enter the directory: cd ~/test_directory wsl","title":"mkdir"},{"location":"tut_bash/#echo","text":"Can be used to print to screen: echo \"Hello\"","title":"echo"},{"location":"tut_bash/#touch","text":"Can be used to create a new (empty) file: touch foo","title":"touch"},{"location":"tut_bash/#rm","text":"Can be used to create delete a file: rm foo","title":"rm"},{"location":"tut_bash/#_1","text":"The carrot sign can be used to send the output to a file: echo \"Hello\" > output.txt","title":"&gt;"},{"location":"tut_bash/#cat","text":"Can be used to print the contents of a file to the screen: cat output.txt","title":"cat"},{"location":"tut_bash/#cp","text":"Can be used to copy a a file: cat output.txt output2.txt","title":"cp"},{"location":"tut_bash/#nano","text":"Nano can be used to edit a file, typing: nano data1.txt Will bring up an editor window: Starting from the top line type: bob 1 fred 2 mary 3 noah 4 sally 5 And then save the file using Ctrl-O and press enter, and quit using Ctrl-X .","title":"nano"},{"location":"tut_bash/#wc","text":"The word count command can be used to count the number of lines or words in a file: wc -l data1.txt","title":"wc"},{"location":"tut_bash/#grep","text":"Can be used to search a file for content: grep \"noah\" data1.text While return all the lines in data1.txt containing the search term \"noah\".","title":"grep"},{"location":"tut_bash/#file-analysis","text":"A very powerful feature of the terminal is the awk programming language, which allows us to extract subsets of a data file, filter data according to some criteria or perform arithmetic operations on the data. awk manipulates a data file by per- forming operations on its columns - this is extremely useful for scientific data sets because typically the columns features or variables of interest. For example, we can use awk to produce a new file that squares the data in our previous file: awk '{print $1,$2*$2}' data1.txt > data2.txt We can also use awk to add up all the squared data values: awk '{X+=$2} END{print $2}' data2.txt","title":"File Analysis"},{"location":"tut_intro/","text":"Introduction Here we present pre-workshop tutorials for bash/shell , R , and Python3 , and Plink . Students who are not already very familiar with these programs are required to complete these tutorials. The first three tutorials do not require any data and can be completed at anytime while the last tutorial (Plink) requires sample data downloaded in Testing . When the workshop begins students will be expected to understand the following: Bash : Navigate filesystem, copy/move/unzip files. Create directories and edit files (using nano). R : Install packages, read from file, manipulate variables, understand functions, create plots. Python : Import libraries, create variables, understand list comprehension, basic plotting. Plink : Explore and genderate GWAS data, recode and reorder allelic data, use PLINK website.","title":"Introduction"},{"location":"tut_intro/#introduction","text":"Here we present pre-workshop tutorials for bash/shell , R , and Python3 , and Plink . Students who are not already very familiar with these programs are required to complete these tutorials. The first three tutorials do not require any data and can be completed at anytime while the last tutorial (Plink) requires sample data downloaded in Testing . When the workshop begins students will be expected to understand the following: Bash : Navigate filesystem, copy/move/unzip files. Create directories and edit files (using nano). R : Install packages, read from file, manipulate variables, understand functions, create plots. Python : Import libraries, create variables, understand list comprehension, basic plotting. Plink : Explore and genderate GWAS data, recode and reorder allelic data, use PLINK website.","title":"Introduction"},{"location":"tut_plink/","text":"Introduction to PLINK (Part I) PLINK is the most popular software program for performing genome-wide association analyses it is extremely extensive, allowing a huge number of analyses to be performed. It also includes many options for reformatting your data and provides useful data summaries. Software packages are usually best learnt by having a go at running some of their basic applications and progressing from there (rather than reading the entire user manual first!) - so we begin by running some basic PLINK commands and then work steadily towards performing more sophisticated analyses through these PLINK tutorials. Sample Data This tutorial runs on the data in the pre-workshop materials downloaded here . If you have followed the previous directions, this data should be in: ~/prsworkshop/preworkshop_materials_(\"your OS\")/Plink/tutorial/sample_data . \u26a0\ufe0f All data used in this workshop are simulated . They have no specific biological meaning and are for demonstration purposes only. After completing this practical, you should be able to: Explore and generate genetic data sets needed for GWAS Recode and reorder allelic data Use the PLINK website Select and exclude lists of samples and SNPs In all of the instructions below: - Anything in between the symbols \\<> needs to be changed in some way. For example, \\<file_name> indicates that you should replace that entire statement (including the \\<> symbols) with the appropriate file name. - Bold indicates non- command-line instructions (e.g. right-click ) Exploring Data To begin the tutorial please navigate to: cd ~/prsworkshop/preworkshop_materials_(\"yourOS\")/Plink/tutorial/sample_data First let's make sure we can call plink from this directory: ../../code/plink Next lets observe the files in the sample data directory: ls We should see the following four files: D1D.map D1D.pcs1234 D1D.ped D1D.pheno1 Let's look each each file by typing the following commands and pressing q to quit after each one: less D1D.map # A map file that associates snps with chromosomal locations less D1D.pcs1234 # A PCA file that lists individuals first four prinicipal components less D1D.ped # A pedigree file that lists individuals genotypes less D1D.pheno1 # A phenotype file that lists individuals phenotypes Next to the PLINK website http://zzz.bwh.harvard.edu/plink/download.shtml and investigate the format of the MAP/PED files (Look in the blue column on the left side). What do you observe? - What are the 4 columns in the map file? - What are the first 6 columns in a ped file? - What information is in the remaining columns of the ped file? Manipulating Data Create 'binary' format PLINK files using the recode command: ../../codeplink --file D1D --make-bed --out D1D List files ( ls ) and check which new files have appeared Examine the files ending .bim and .fam. Do not open the .bed file. Examine the '.log' file. What do you observe? How is the fam file similar to the ped file? How is it different? How is the bim file similar to the map file? How is it different? (Use the PLINK website if necessary) Recoding alleles as counts Genotype data in allele count format is very useful, for example to use in regression modelling in statistical software such as R. Generate the D1D data in allele count format: ../../code/plink --bfile D1D --recodeA --out D1D_AC \ud83d\udcdd There are several options for recoding SNPs in different ways - more information on the PLINK website (see next section). Again note that a log file was created - skim the log file or screen output Look inside the .raw file. What do you think the 0/1/2 represent? Do there appear to be more 0s or 2s? Why might this be? PLINK website Go to http://zzz.bwh.harvard.edu/plink/download.shtml and skim through the front page to get an idea of PLINK's functionality. Note the list of clickable links on the left side of the website. Under 'Data Management' (click the heading on the left) and read the list of the di\ufb00erent ways you may want to recode and reorder data sets. Don't attempt to read much further as this is a very large and detailed section - a useful future resource but too much for today. Under 'Data Management', click 'Write SNP list' and read the instructions there to write SNP lists. Write SNP list and extract SNPs You will now use the information that you found on the PLINK website to create a command to extract a list of SNPs. Below is a list of requirements - try to do this before you go to the end of this section, where the full command is given and explained. Set the D1D binary file as input Set MAF threshold to 0.05 Set SNP missingness threshold to 0.05 Add the appropriate command to write out a snp list containing only those SNPs with MAF above 0.05 and missingness below 0.05 Use 'D1D_snps' as the output file name After the command has run, check the output for your SNP list and look at it with the default viewer. You will now use the SNP list that you have created to extract those SNPs and create a new set of data files in a single command. Use the D1D binary file set as input Find the command for extracting a set of SNPs listed in a file (hint: Data Management section) and combine it with a command that you learned above to create binary files Use the output file name 'D1D_MAF_MISS' \ud83d\udcdd Log files are uselful to check that the number of SNPs and samples is as expected. Always check your your log files to ensure that they are sensible. SNP lists can also be used to EXCLUDE SNPs - select 'exclude' above instead of 'extract'. Sample ID lists can also be used to 'keep' or 'remove' individuals in the same 'filter' window. Note that both sample IDs (FID IID,separated by a space are required in the sample file list. Solution 1: TO BE REVEALED LATER!! Solution 2: TO BE REVEALED LATER!! Performing QC & GWAS (Part II) Here we will work on the following skills: Generate summaries of the data needed for QC Apply QC thresholds Perform GWAS Generate summaries to perform QC There are many kinds of summaries of the data that can generated in PLINK in order to perform particular quality control (QC) steps, which help to make our data more reliable. Some of these involve summaries in relation to the individuals (e.g. individual missingness, sex-check) and some relate to summaries of SNP data (e.g. MAF, Hardy-Weinburg Equilibrium). Over the next few sub-sections you will go through some examples of generating summary statistics that can be used to perform QC. Individual missingness Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Open the 2 files that were generated (lmiss & imiss). What do the two output files contain? In the imiss file, what is the meaning of the data in the column headed \"F_MISS\"? SNP Missingness Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Look inside the file containing SNP missingness information: D1D_miss.lmiss. What is the meaning of the value under F_MISS? What does the command --test-missing do and why might it be useful? Hardy-Weinberg Equilibrium Generate HWE statistics using the --hardy option. Use output file name D1D_hardy. Open and examine results. Why are there multiple rows for each SNP and what does each mean? Which of the rows do you think should be used to exclude SNPs from the subsequent analysis (if any) for failing the HWE test? Why? Allele frequencies Generate allele frequencies using the command *--*freq. Use D1D_freq as the output name. Examine the output. What is the heading of the column that tells you which nucleotide is the minor allele? \ud83d\udcdd This information is important to remember as many PLINK files use this notation. The minor allele is always labeled the same way Apply QC filters There are di\ufb00erent strategies for performing QC on your data: (a) Create lists of SNPs and individuals and use --remove, --extract, --exclude, --include to create new file sets (good for documentation, collaboration) (b) Apply thresholds one at a time and generate new bed/bim/fam file (good for applying sequential filters) (c) Use options (e.g. --maf ) in other commands (e.g. --assoc) to remove SNPs or samples at required QC thresholds during analysis. \ud83d\udcdd We have already seen how to select or exclude individuals or SNPs by first creating lists (a), so in this section we will set thresholds to generate new files sets in a single command. However, it is useful to have lists of all SNPs and individuals excluded pre-analysis, according to the reason for exclusion, so generating and retaining such files using the techniques that we used before for good practice. Apply individual missingness thresholds Generate new binary file sets (--make-bed) from the 'D1D' binary file set, removing individuals with missingness greater than 3% using a single command (hint: In the 'Inclusion thresholds' section, see the 'Missing/person' sub-section). Use the output file name 'D1D_imiss3pc' Examine the output files (no need to open, and remember the bed file cannot be read) and the log file How many individuals were in the original file? How many individuals were removed? How many males and females were left after screening? Apply SNP missingness and MAF thresholds Create new binary file sets from the 'D1D_imiss3pc' binary file set (NOT the original D1D files) by setting MAF threshold to 0.05 and SNP missingness threshold to 0.02 (See 'Inclusion thresholds' to obtain the correct threshold flags). Use the output file name'D1D_imiss3pc_lmiss2pc_maf5pc Examine the output files and the log file How many SNPs were in the original files? How many SNPs were removed for low minor allele frequency? How many SNPs were removed for missingness? Apply Hardy-Weinberg thresholds Generate a new binary file set called 'D1D_QC' from the D1D_imiss3pc_lmiss2pc_maf5pc file, applying a HWE threshold of 0.0001. This is our final, QC'ed file set. Examine log and output files. -How many SNPs were removed for HWE p-values below the threshold? \ud83d\udcdd It is useful to know how to do this, but be careful about setting this threshold - strong association signals can cause departure from HWE and you may remove great results! Use a lenient threshold and apply to controls only to avoid this problem. HWE can also be checked post-hoc for each SNP. Perform GWAS Case/Control GWAS - no covariates Run the following code, which performs a genetic association study using logistic regression on some case/control data: ../../code/plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --out D1D_CC What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Are there any other significant associations? Case/Control GWAS - with covariates Here we repeat the previous analysis but this time including some covariates. The file D1D.pcs1234 contains the first 4 principal components from a PCA on the genetic data. Run the analysis specifying the covariates file: ../../code/plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --covar D1D.pcs.1234 --out D1D_CC_PCadj What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Suggest a reason for the different results when adjusting for the 4 PCs?","title":"Plink Tutorial"},{"location":"tut_plink/#introduction-to-plink-part-i","text":"PLINK is the most popular software program for performing genome-wide association analyses it is extremely extensive, allowing a huge number of analyses to be performed. It also includes many options for reformatting your data and provides useful data summaries. Software packages are usually best learnt by having a go at running some of their basic applications and progressing from there (rather than reading the entire user manual first!) - so we begin by running some basic PLINK commands and then work steadily towards performing more sophisticated analyses through these PLINK tutorials.","title":"Introduction to PLINK  (Part I)"},{"location":"tut_plink/#sample-data","text":"This tutorial runs on the data in the pre-workshop materials downloaded here . If you have followed the previous directions, this data should be in: ~/prsworkshop/preworkshop_materials_(\"your OS\")/Plink/tutorial/sample_data . \u26a0\ufe0f All data used in this workshop are simulated . They have no specific biological meaning and are for demonstration purposes only. After completing this practical, you should be able to: Explore and generate genetic data sets needed for GWAS Recode and reorder allelic data Use the PLINK website Select and exclude lists of samples and SNPs In all of the instructions below: - Anything in between the symbols \\<> needs to be changed in some way. For example, \\<file_name> indicates that you should replace that entire statement (including the \\<> symbols) with the appropriate file name. - Bold indicates non- command-line instructions (e.g. right-click )","title":"Sample Data"},{"location":"tut_plink/#exploring-data","text":"To begin the tutorial please navigate to: cd ~/prsworkshop/preworkshop_materials_(\"yourOS\")/Plink/tutorial/sample_data First let's make sure we can call plink from this directory: ../../code/plink Next lets observe the files in the sample data directory: ls We should see the following four files: D1D.map D1D.pcs1234 D1D.ped D1D.pheno1 Let's look each each file by typing the following commands and pressing q to quit after each one: less D1D.map # A map file that associates snps with chromosomal locations less D1D.pcs1234 # A PCA file that lists individuals first four prinicipal components less D1D.ped # A pedigree file that lists individuals genotypes less D1D.pheno1 # A phenotype file that lists individuals phenotypes Next to the PLINK website http://zzz.bwh.harvard.edu/plink/download.shtml and investigate the format of the MAP/PED files (Look in the blue column on the left side). What do you observe? - What are the 4 columns in the map file? - What are the first 6 columns in a ped file? - What information is in the remaining columns of the ped file?","title":"Exploring Data"},{"location":"tut_plink/#manipulating-data","text":"Create 'binary' format PLINK files using the recode command: ../../codeplink --file D1D --make-bed --out D1D List files ( ls ) and check which new files have appeared Examine the files ending .bim and .fam. Do not open the .bed file. Examine the '.log' file. What do you observe? How is the fam file similar to the ped file? How is it different? How is the bim file similar to the map file? How is it different? (Use the PLINK website if necessary)","title":"Manipulating Data"},{"location":"tut_plink/#recoding-alleles-as-counts","text":"Genotype data in allele count format is very useful, for example to use in regression modelling in statistical software such as R. Generate the D1D data in allele count format: ../../code/plink --bfile D1D --recodeA --out D1D_AC \ud83d\udcdd There are several options for recoding SNPs in different ways - more information on the PLINK website (see next section). Again note that a log file was created - skim the log file or screen output Look inside the .raw file. What do you think the 0/1/2 represent? Do there appear to be more 0s or 2s? Why might this be?","title":"Recoding alleles as counts"},{"location":"tut_plink/#plink-website","text":"Go to http://zzz.bwh.harvard.edu/plink/download.shtml and skim through the front page to get an idea of PLINK's functionality. Note the list of clickable links on the left side of the website. Under 'Data Management' (click the heading on the left) and read the list of the di\ufb00erent ways you may want to recode and reorder data sets. Don't attempt to read much further as this is a very large and detailed section - a useful future resource but too much for today. Under 'Data Management', click 'Write SNP list' and read the instructions there to write SNP lists.","title":"PLINK website"},{"location":"tut_plink/#write-snp-list-and-extract-snps","text":"You will now use the information that you found on the PLINK website to create a command to extract a list of SNPs. Below is a list of requirements - try to do this before you go to the end of this section, where the full command is given and explained. Set the D1D binary file as input Set MAF threshold to 0.05 Set SNP missingness threshold to 0.05 Add the appropriate command to write out a snp list containing only those SNPs with MAF above 0.05 and missingness below 0.05 Use 'D1D_snps' as the output file name After the command has run, check the output for your SNP list and look at it with the default viewer. You will now use the SNP list that you have created to extract those SNPs and create a new set of data files in a single command. Use the D1D binary file set as input Find the command for extracting a set of SNPs listed in a file (hint: Data Management section) and combine it with a command that you learned above to create binary files Use the output file name 'D1D_MAF_MISS' \ud83d\udcdd Log files are uselful to check that the number of SNPs and samples is as expected. Always check your your log files to ensure that they are sensible. SNP lists can also be used to EXCLUDE SNPs - select 'exclude' above instead of 'extract'. Sample ID lists can also be used to 'keep' or 'remove' individuals in the same 'filter' window. Note that both sample IDs (FID IID,separated by a space are required in the sample file list. Solution 1: TO BE REVEALED LATER!! Solution 2: TO BE REVEALED LATER!!","title":"Write SNP list and extract SNPs"},{"location":"tut_plink/#performing-qc-gwas-part-ii","text":"Here we will work on the following skills: Generate summaries of the data needed for QC Apply QC thresholds Perform GWAS","title":"Performing QC &amp; GWAS (Part II)"},{"location":"tut_plink/#generate-summaries-to-perform-qc","text":"There are many kinds of summaries of the data that can generated in PLINK in order to perform particular quality control (QC) steps, which help to make our data more reliable. Some of these involve summaries in relation to the individuals (e.g. individual missingness, sex-check) and some relate to summaries of SNP data (e.g. MAF, Hardy-Weinburg Equilibrium). Over the next few sub-sections you will go through some examples of generating summary statistics that can be used to perform QC.","title":"Generate summaries to perform QC"},{"location":"tut_plink/#individual-missingness","text":"Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Open the 2 files that were generated (lmiss & imiss). What do the two output files contain? In the imiss file, what is the meaning of the data in the column headed \"F_MISS\"?","title":"Individual missingness"},{"location":"tut_plink/#snp-missingness","text":"Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Look inside the file containing SNP missingness information: D1D_miss.lmiss. What is the meaning of the value under F_MISS? What does the command --test-missing do and why might it be useful?","title":"SNP Missingness"},{"location":"tut_plink/#hardy-weinberg-equilibrium","text":"Generate HWE statistics using the --hardy option. Use output file name D1D_hardy. Open and examine results. Why are there multiple rows for each SNP and what does each mean? Which of the rows do you think should be used to exclude SNPs from the subsequent analysis (if any) for failing the HWE test? Why?","title":"Hardy-Weinberg Equilibrium"},{"location":"tut_plink/#allele-frequencies","text":"Generate allele frequencies using the command *--*freq. Use D1D_freq as the output name. Examine the output. What is the heading of the column that tells you which nucleotide is the minor allele? \ud83d\udcdd This information is important to remember as many PLINK files use this notation. The minor allele is always labeled the same way","title":"Allele frequencies"},{"location":"tut_plink/#apply-qc-filters","text":"","title":"Apply QC filters"},{"location":"tut_plink/#there-are-different-strategies-for-performing-qc-on-your-data","text":"(a) Create lists of SNPs and individuals and use --remove, --extract, --exclude, --include to create new file sets (good for documentation, collaboration) (b) Apply thresholds one at a time and generate new bed/bim/fam file (good for applying sequential filters) (c) Use options (e.g. --maf ) in other commands (e.g. --assoc) to remove SNPs or samples at required QC thresholds during analysis. \ud83d\udcdd We have already seen how to select or exclude individuals or SNPs by first creating lists (a), so in this section we will set thresholds to generate new files sets in a single command. However, it is useful to have lists of all SNPs and individuals excluded pre-analysis, according to the reason for exclusion, so generating and retaining such files using the techniques that we used before for good practice.","title":"There are di\ufb00erent strategies for performing QC on your data:"},{"location":"tut_plink/#apply-individual-missingness-thresholds","text":"Generate new binary file sets (--make-bed) from the 'D1D' binary file set, removing individuals with missingness greater than 3% using a single command (hint: In the 'Inclusion thresholds' section, see the 'Missing/person' sub-section). Use the output file name 'D1D_imiss3pc' Examine the output files (no need to open, and remember the bed file cannot be read) and the log file How many individuals were in the original file? How many individuals were removed? How many males and females were left after screening?","title":"Apply individual missingness thresholds"},{"location":"tut_plink/#apply-snp-missingness-and-maf-thresholds","text":"Create new binary file sets from the 'D1D_imiss3pc' binary file set (NOT the original D1D files) by setting MAF threshold to 0.05 and SNP missingness threshold to 0.02 (See 'Inclusion thresholds' to obtain the correct threshold flags). Use the output file name'D1D_imiss3pc_lmiss2pc_maf5pc Examine the output files and the log file How many SNPs were in the original files? How many SNPs were removed for low minor allele frequency? How many SNPs were removed for missingness?","title":"Apply SNP missingness and MAF thresholds"},{"location":"tut_plink/#apply-hardy-weinberg-thresholds","text":"Generate a new binary file set called 'D1D_QC' from the D1D_imiss3pc_lmiss2pc_maf5pc file, applying a HWE threshold of 0.0001. This is our final, QC'ed file set. Examine log and output files. -How many SNPs were removed for HWE p-values below the threshold? \ud83d\udcdd It is useful to know how to do this, but be careful about setting this threshold - strong association signals can cause departure from HWE and you may remove great results! Use a lenient threshold and apply to controls only to avoid this problem. HWE can also be checked post-hoc for each SNP.","title":"Apply Hardy-Weinberg thresholds"},{"location":"tut_plink/#perform-gwas","text":"","title":"Perform GWAS"},{"location":"tut_plink/#casecontrol-gwas-no-covariates","text":"Run the following code, which performs a genetic association study using logistic regression on some case/control data: ../../code/plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --out D1D_CC What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Are there any other significant associations?","title":"Case/Control GWAS - no covariates"},{"location":"tut_plink/#casecontrol-gwas-with-covariates","text":"Here we repeat the previous analysis but this time including some covariates. The file D1D.pcs1234 contains the first 4 principal components from a PCA on the genetic data. Run the analysis specifying the covariates file: ../../code/plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --covar D1D.pcs.1234 --out D1D_CC_PCadj What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Suggest a reason for the different results when adjusting for the 4 PCs?","title":"Case/Control GWAS - with covariates"},{"location":"tut_python/","text":"Introduction to Python Python is a useful general purpose programming language. Here we will go over some basic python commands from an interactive shell. To being open python3 by typing: python3 Libraries Downloaded python libraries can be imported interactively: import matplotlib.pyplot as plt Variables in Python You can assign a value or values to any variable you want using the equals sign: X = 5 # X is an integer (5) X = [1,2,3,4,5] # X is a list containing the first five integers Functions can also be used: X = range(-10,11,1) # X includes all integers between -10 and 10 counting by 1 New variables can be declared with lists: Y = [x*x for x in X] # Y is equal to X squared A figure can be generated: plt.plot(X,Y) And viewed: plt.show()","title":"Python Tutorial"},{"location":"tut_python/#introduction-to-python","text":"Python is a useful general purpose programming language. Here we will go over some basic python commands from an interactive shell. To being open python3 by typing: python3","title":"Introduction to Python"},{"location":"tut_python/#libraries","text":"Downloaded python libraries can be imported interactively: import matplotlib.pyplot as plt","title":"Libraries"},{"location":"tut_python/#variables-in-python","text":"You can assign a value or values to any variable you want using the equals sign: X = 5 # X is an integer (5) X = [1,2,3,4,5] # X is a list containing the first five integers Functions can also be used: X = range(-10,11,1) # X includes all integers between -10 and 10 counting by 1 New variables can be declared with lists: Y = [x*x for x in X] # Y is equal to X squared A figure can be generated: plt.plot(X,Y) And viewed: plt.show()","title":"Variables in Python"}]}