---
title: "PRS Africa - Group 4 Project"
author: "Michaela O'Hare"
date: "`r Sys.Date()`"
output:
  word_document:
    toc: true
    fig_width: 7
    fig_height: 4
editor_options:
  chunk_output_type: console
---

# Loading data and packages

```{r}

# Load packages

library(dplyr)
library(glmnet)
library(ggplot2)
library(caret)

```

```{r}

# Load data

eosdta <- read.table("~/University/PhD/Conferences and Workshops/2024/PRS Wellcome Uganda/Content/Group Project/eosdta.txt", quote="\"", comment.char="", head = T)

```

# Manipulating data

```{r}

# Split the data

## 80% of the sample size
smp_size <- floor(0.80 * nrow(eosdta))

## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(eosdta)), size = smp_size)

## 
train <- eosdta[train_ind, ]
test <- eosdta[-train_ind, ]

```


```{r}

# remove covariates from training data

selected_train <- train %>%
  select(eos, starts_with("PGS"))

# remove covariates from test data

selected_test <- test %>%
  select(eos, starts_with("PGS"))

```

# Running Elastic Net Regression

``` {r}

# Format the data into X and Y

X <- selected_train %>% 
	select(starts_with("PGS")) %>% 
	scale(center = TRUE, scale = FALSE) %>% 
	as.matrix()


Y <- selected_train %>% 
	select(eos) %>% 
	as.matrix() 

```



```{r}

# Model Building : Elastic Net Regression

control <- trainControl(method = "repeatedcv", 
							number = 5, 
							repeats = 5, 
							search = "random", 
							verboseIter = TRUE) 

```



```{r}

# Training Elastic Net Regression model 

elastic_model <- train(eos ~ ., 
						data = cbind(X, Y), 
						method = "glmnet", 
						preProcess = c("center", "scale"), 
						tuneLength = 25, 
						trControl = control) 

elastic_model 


best_lambda <- elastic_model$bestTune$lambda
best_model <- elastic_model$finalModel
coefficients <- coef(best_model, s = best_lambda)

```

# Applying Elastic Net Regression to training dataset

```{r}

# Select the PGS with non-zero values

# Assuming 'coefficients' is the coefficients object from the model
coefficients <- as.matrix(coefficients)

# Convert to data frame
coef_df <- as.data.frame(coefficients)

# Assign column names
names(coef_df) <- "Value"

# Filter rows with non-zero coefficients
non_zero_coef_df <- coef_df[coef_df$Value != 0, , drop = FALSE]

```



```{r}

# select PGS from original training dataset

selected_PGS = c("PGS000090", "PGS001172", "PGS002364", "PGS002544", "PGS002642")

selected_PGS_df_train = selected_train[,selected_PGS]

# Extract weights from non_zero_coef_df (excluding intercept)
weights <- non_zero_coef_df[-1, "Value"]

# Perform weighted sum across columns of selected_PGS_df
PRSmix_train <- rowSums(selected_PGS_df_train[, selected_PGS] * weights)

# Append to training dataset

train$PRSmix_train = PRSmix_train

```


# Applying Elastic Net Regression model to test dataset

```{r}

# select PGS from testing dataset

selected_PGS_df_test = selected_test[,selected_PGS]

# Perform weighted sum across columns of selected_PGS_df
PRSmix_test <- rowSums(selected_PGS_df_test[, selected_PGS] * weights)

# Append to test dataset

test$PRSmix_test = PRSmix_test

```


# Generating linear regression models to find predictivity in training and test datasets

```{r}

# Generate the full model for training data

full_train = lm(eos ~ PRSmix_train + age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = train)

# Fit your second linear regression model
null_train <- lm(eos ~ age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = train)

# Extract adjusted R^2 for model1
adj_rsq2_full_train <- summary(full_train)$adj.r.squared

# Extract adjusted R^2 for model2
adj_rsq2_null_train <- summary(null_train)$adj.r.squared

# Calculate the difference in adjusted R^2
PRS_adj_rsq2_train <- adj_rsq2_full_train - adj_rsq2_null_train

cat("Difference in Adjusted R^2:", PRS_adj_rsq2_train, "\n")

summary(full_train)


```

```{r}

# Generate the full model for testing data

full_test = lm(eos ~ PRSmix_test + age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = test)

# Fit your second linear regression model
null_test <- lm(eos ~ age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = test)

# Extract adjusted R^2 for model1
adj_rsq2_full_test <- summary(full_test)$adj.r.squared

# Extract adjusted R^2 for model2
adj_rsq2_null_test <- summary(null_test)$adj.r.squared

# Calculate the difference in adjusted R^2
PRS_adj_rsq2_test <- adj_rsq2_full_test - adj_rsq2_null_test

cat("Difference in Adjusted R^2:", PRS_adj_rsq2_test, "\n")

summary(full_test)

```


# Plotting adjusted R^2 values 

```{r}

# TRAINING DATASET

# Subset columns starting with "PGS" or "PRS" and other necessary predictors
X_cols <- grep("^PGS|^PRS", names(train), value = TRUE)
predictors <- c(X_cols, "age", "sex", paste0("PC", 1:10))

# Initialize vectors to store adjusted R-squared values
adjusted_rsq <- numeric(length(X_cols))

# Iterate over each predictor set (each column starting with PGS or PRS)
for (i in seq_along(X_cols)) {
  # Create the formula for lm() with current X_col as predictor
  formula <- paste("eos ~", paste(predictors[i], collapse = " + "))
  
  # Fit the linear regression model
  model <- lm(formula, data = train)
  
  # Extract adjusted R-squared and store it
  adjusted_rsq[i] <- summary(model)$adj.r.squared
}

# Create a data frame for plotting
plot_data <- data.frame(Predictor = X_cols, Adjusted_R_squared = adjusted_rsq)

# Plotting using ggplot2
ggplot(plot_data, aes(x = Predictor, y = Adjusted_R_squared)) +
  geom_bar(stat = "identity", fill = "skyblue", width = 0.5) +
  labs(title = "Adjusted R-squared of PGS in training dataset",
       x = "PGS",
       y = "Adjusted R-squared") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip()


```

```{r}


# TEST DATASET

# Subset columns starting with "PGS" or "PRS" and other necessary predictors
X_cols <- grep("^PGS|^PRS", names(test), value = TRUE)
predictors <- c(X_cols, "age", "sex", paste0("PC", 1:10))

# Initialize vectors to store adjusted R-squared values
adjusted_rsq <- numeric(length(X_cols))

# Iterate over each predictor set (each column starting with PGS or PRS)
for (i in seq_along(X_cols)) {
  # Create the formula for lm() with current X_col as predictor
  formula <- paste("eos ~", paste(predictors[i], collapse = " + "))
  
  # Fit the linear regression model
  model <- lm(formula, data = test)
  
  # Extract adjusted R-squared and store it
  adjusted_rsq[i] <- summary(model)$adj.r.squared
}

# Create a data frame for plotting
plot_data <- data.frame(Predictor = X_cols, Adjusted_R_squared = adjusted_rsq)

# Plotting using ggplot2
ggplot(plot_data, aes(x = Predictor, y = Adjusted_R_squared)) +
  geom_bar(stat = "identity", fill = "skyblue", width = 0.5) +
  labs(title = "Adjusted R-squared by PGS in the test dataset",
       x = "PGS",
       y = "Adjusted R-squared") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip()


```




